{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m2024-10-22 21:59:57 - analysis-df-assembly - INFO - Modules loaded.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import geopandas as gpd \n",
    "import numpy as np \n",
    "import json \n",
    "from glob import glob \n",
    "\n",
    "import sys \n",
    "sys.path.append(\"../\")\n",
    "from logger import setup_logger\n",
    "logger = setup_logger(\"analysis-df-assembly\")\n",
    "logger.setLevel(\"INFO\")\n",
    "\n",
    "import os \n",
    "\n",
    "logger.info(\"Modules loaded.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "ICAR_NONE_RUN='../runs/icar_none/simulated_False/ahl_True/20241021-1038'\n",
    "ICAR_CHEATING_RUN='../runs/icar_cheating/simulated_False/ahl_True/20241022-1130'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m2024-10-22 21:59:57 - analysis-df-assembly - INFO - Found 2 ICAR_NONE estimates and 3 ICAR_CHEATING estimates.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "ICAR_NONE_ESTIMATES = glob(f\"{ICAR_NONE_RUN}/estimate*.csv\")\n",
    "ICAR_CHEATING_ESTIMATES = glob(f\"{ICAR_CHEATING_RUN}/estimate*.csv\")\n",
    "logger.info(f\"Found {len(ICAR_NONE_ESTIMATES)} ICAR_NONE estimates and {len(ICAR_CHEATING_ESTIMATES)} ICAR_CHEATING estimates.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "icar_cheating_estimates = {} \n",
    "for f in ICAR_CHEATING_ESTIMATES:\n",
    "    df = pd.read_csv(f)\n",
    "    df['tract_id'] = df['tract_id'].astype(int).astype(str)\n",
    "    icar_cheating_estimates[os.path.splitext(os.path.basename(f))[0]] = df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "icar_none_estimates = {} \n",
    "for f in ICAR_NONE_ESTIMATES:\n",
    "    df = pd.read_csv(f)\n",
    "    df['tract_id'] = df['tract_id'].astype(int).astype(str)\n",
    "    icar_none_estimates[os.path.splitext(os.path.basename(f)[0])] = df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m2024-10-22 21:59:57 - analysis-df-assembly - INFO - Using smoothed estimates.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "USE_SMOOTHING = True \n",
    "if USE_SMOOTHING: \n",
    "    icar_model_estimates = icar_cheating_estimates\n",
    "    logger.info(\"Using smoothed estimates.\")\n",
    "else:\n",
    "    icar_model_estimates = icar_none_estimates\n",
    "    logger.info(\"Using unsmoothed estimates.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m2024-10-22 21:59:57 - analysis-df-assembly - INFO - Loaded NYC CT shapefile with 2325 CTs.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "ct_nyc = gpd.read_file('geo/data/ct-nyc-wi-2020.geojson')\n",
    "\n",
    "\n",
    "TO_DROP = ['OBJECTID','BoroCode','CT2020','CDEligibil','NTA2020','CDTA2020','Shape__Area','Shape__Length','geometry']\n",
    "ct_nyc.drop(columns=TO_DROP, inplace=True)\n",
    "\n",
    "logger.info(f\"Loaded NYC CT shapefile with {len(ct_nyc.index)} CTs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CTLabel', 'BoroName', 'BoroCT2020', 'NTAName', 'CDTANAME', 'GEOID',\n",
       "       'PUMA'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct_nyc.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m2024-10-22 21:59:58 - analysis-df-assembly - INFO - Loaded NYC CT (water clipped) shapefile with 2327 CTs.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "ct_nyc_clip = gpd.read_file('geo/data/ct-nyc-2020.geojson')\n",
    "logger.info(f\"Loaded NYC CT (water clipped) shapefile with {len(ct_nyc_clip.index)} CTs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m2024-10-22 21:59:58 - analysis-df-assembly - INFO - Merged NYC CT shapefile with icar model estimates.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "ct_nyc = ct_nyc.merge(icar_model_estimates['estimate_p_y'], left_on='GEOID', right_on='tract_id', suffixes=('_ct', '_p_y'))\n",
    "ct_nyc = ct_nyc.merge(icar_model_estimates['estimate_at_least_one_positive_image_by_area'], left_on='GEOID', right_on='tract_id', suffixes=('_ct', '_p_alop'))\n",
    "ct_nyc = ct_nyc.merge(icar_model_estimates['estimate_at_least_one_positive_image_by_area_if_you_have_100_images'], left_on='GEOID', right_on='tract_id', suffixes=('_ct', '_p_alop_100'))\n",
    "\n",
    "# drop empirical_estimate_* cols \n",
    "TO_DROP = [c for c in ct_nyc.columns if 'empirical_estimate_' in c]\n",
    "ct_nyc.drop(columns=TO_DROP, inplace=True)\n",
    "\n",
    "logger.info(f\"Merged NYC CT shapefile with icar model estimates.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "dp05_nyc_md = pd.read_json('demo/data/acs22_dp05_md.json')\n",
    "\n",
    "# Normalize the 'variables' column in the JSON\n",
    "dp05_nyc_md = pd.json_normalize(dp05_nyc_md['variables']).set_index(dp05_nyc_md.index)\n",
    "\n",
    "# Parse out the 'label' column\n",
    "# In all rows of the 'label', get the lowest and highest number of '!!'\n",
    "min_sep = min(dp05_nyc_md['label'].apply(lambda x: x.count('!!')))\n",
    "max_sep = max(dp05_nyc_md['label'].apply(lambda x: x.count('!!')))\n",
    "\n",
    "# Create 'desc_i' columns for each level of '!!'\n",
    "for i in range(min_sep + 1, max_sep + 2):  # Adjusting range to account for correct indexing\n",
    "    dp05_nyc_md[f'desc_{i}'] = dp05_nyc_md['label'].apply(\n",
    "        lambda x: x.split('!!')[i-1] if len(x.split('!!')) >= i else None\n",
    "    )\n",
    "\n",
    "# drop TO_DROP \n",
    "TO_DROP = ['label','concept','predicateType','group','limit','predicateOnly']\n",
    "dp05_nyc_md = dp05_nyc_md.drop(columns=TO_DROP)\n",
    "\n",
    "desc_1_filter = ['Estimate']\n",
    "dp05_nyc_md = dp05_nyc_md[dp05_nyc_md['desc_1'].isin(desc_1_filter)]\n",
    "\n",
    "# Output the modified dataframe\n",
    "# display all rows \n",
    "dp05_nyc_md = dp05_nyc_md.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nhl_white_alone</th>\n",
       "      <th>nhl_black_alone</th>\n",
       "      <th>hispanic_alone</th>\n",
       "      <th>nhl_asian_alone</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tract_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36005000100</th>\n",
       "      <td>1098</td>\n",
       "      <td>2000</td>\n",
       "      <td>1172</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36005000200</th>\n",
       "      <td>83</td>\n",
       "      <td>1281</td>\n",
       "      <td>3109</td>\n",
       "      <td>299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36005000400</th>\n",
       "      <td>283</td>\n",
       "      <td>1559</td>\n",
       "      <td>4212</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36005001600</th>\n",
       "      <td>106</td>\n",
       "      <td>2132</td>\n",
       "      <td>3507</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36005001901</th>\n",
       "      <td>306</td>\n",
       "      <td>942</td>\n",
       "      <td>842</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36085030302</th>\n",
       "      <td>2209</td>\n",
       "      <td>1568</td>\n",
       "      <td>1625</td>\n",
       "      <td>918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36085031901</th>\n",
       "      <td>289</td>\n",
       "      <td>1626</td>\n",
       "      <td>1469</td>\n",
       "      <td>224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36085031902</th>\n",
       "      <td>473</td>\n",
       "      <td>2388</td>\n",
       "      <td>1913</td>\n",
       "      <td>217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36085032300</th>\n",
       "      <td>109</td>\n",
       "      <td>421</td>\n",
       "      <td>394</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36085990100</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2327 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "0           nhl_white_alone nhl_black_alone hispanic_alone nhl_asian_alone\n",
       "tract_id                                                                  \n",
       "36005000100            1098            2000           1172             123\n",
       "36005000200              83            1281           3109             299\n",
       "36005000400             283            1559           4212             103\n",
       "36005001600             106            2132           3507             148\n",
       "36005001901             306             942            842               0\n",
       "...                     ...             ...            ...             ...\n",
       "36085030302            2209            1568           1625             918\n",
       "36085031901             289            1626           1469             224\n",
       "36085031902             473            2388           1913             217\n",
       "36085032300             109             421            394              21\n",
       "36085990100               0               0              0               0\n",
       "\n",
       "[2327 rows x 4 columns]"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dp05_nyc = pd.read_json('demo/data/acs22_dp05.json', orient='records')\n",
    "\n",
    "dp05_nyc.columns = dp05_nyc.iloc[0]\n",
    "dp05_nyc = dp05_nyc[1:]\n",
    "\n",
    "dp05_nyc['tract_id'] = dp05_nyc['GEO_ID'].str.split('US', expand=True)[1]\n",
    "\n",
    "RACE_COLS = {\n",
    "    'DP05_0079E': 'nhl_white_alone', \n",
    "    'DP05_0080E': 'nhl_black_alone', \n",
    "    'DP05_0073E': 'hispanic_alone', \n",
    "    'DP05_0082E': 'nhl_asian_alone'\n",
    "}\n",
    "\n",
    "race_nyc = dp05_nyc[list(RACE_COLS.keys())]\n",
    "race_nyc.columns = race_nyc.columns.map(lambda x: RACE_COLS[x])\n",
    "race_nyc.index = dp05_nyc['tract_id']\n",
    "race_nyc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_nyc = ct_nyc.merge(race_nyc, left_on='GEOID', right_index=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-10-22 22:00:45 - analysis-df-assembly - SUCCESS - No NA values found in columns.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "COLS_ALLOWED_NA_VALS = ['empirical_estimate']\n",
    "def na_validation(df, cols_allowed_na_vals):\n",
    "    for c in df.columns:\n",
    "        if c in cols_allowed_na_vals:\n",
    "            continue\n",
    "        if df[c].isna().sum() > 0:\n",
    "            logger.error(f\"Column {c} has {df[c].isna().sum()} NA values.\")\n",
    "    else: \n",
    "        logger.success(\"No NA values found in columns.\")\n",
    "na_validation(ct_nyc, COLS_ALLOWED_NA_VALS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_nyc = ct_nyc.set_index('GEOID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_nyc.to_csv('analysis_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
